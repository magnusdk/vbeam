{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beamforming With Optimized Scans\n",
    "vbeam is built on top of high-level abstractions — we write Numpy-like code, wrap it with `jax.jit`, and hope for the best. We therefore do not have access to the same low-level optimizations that we would have if the beamformer was written in a language like C++ and CUDA. We are limited to high-level optimizations. One such optimization is simply doing less work. By filtering out redundant points from the scan, _before beamforming_, we can get a much faster beamformer. In this notebook we will explore how to perform such an optimization/pre-processing in vbeam.\n",
    "\n",
    "The dataset used is a phased array, focused transmit, cardiac dataset, consisting of 64 elements, and 101 transmit events [1]. Since it is a phased array, we use a sector scan with 256 azimuths and 512 depth samples.\n",
    "\n",
    "Let's (download and) import it!\n",
    "\n",
    "_[1] A. Rodriguez-Molares, O. M. H. Rindal, O. Bernard, etal., “The UltraSound ToolBox,” in 2017 IEEE International Ultrasonics Symposium (IUS), ISSN: 1948-5727,Sep. 2017, pp. 1–4. DOI: 10 . 1109 / ULTSYM . 2017 .8092389._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as np\n",
    "import pyuff_ustb as pyuff\n",
    "\n",
    "from vbeam.data_importers import import_pyuff\n",
    "from vbeam.scan import sector_scan\n",
    "from vbeam.util.download import cached_download\n",
    "\n",
    "# Download and read the channel data\n",
    "data_url = \"http://www.ustb.no/datasets/Verasonics_P2-4_parasternal_long_small.uff\"\n",
    "uff = pyuff.Uff(cached_download(data_url))\n",
    "channel_data = uff.read(\"/channel_data\")\n",
    "\n",
    "# Import the data\n",
    "setup = import_pyuff(channel_data, frames=0)\n",
    "\n",
    "# Define and set a custom sector scan\n",
    "scan_angles = np.array([wave.source.azimuth for wave in channel_data.sequence])\n",
    "scan_depths = np.linspace(0, 110e-3, 512)\n",
    "scan = sector_scan(scan_angles, scan_depths).resize(azimuths=256)\n",
    "setup.scan = scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beamforming the Full Sector Scan\n",
    "Let's create a basic DAS beamformer from our setup, run it on our imported data, and plot the result. We also time the beamformer. By calling `.block_until_ready()` on the result, we ensure that not more than one beamforming job is running at the same time on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vbeam.beamformers import get_das_beamformer\n",
    "\n",
    "beamformer = jax.jit(get_das_beamformer(setup))  # jax.jit makes it run fast\n",
    "result = beamformer(**setup.data)\n",
    "plt.imshow(result.T, aspect=\"auto\", cmap=\"gray\")\n",
    "\n",
    "data = setup.data\n",
    "%timeit beamformer(**data).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running on an Nvidia A100 40GB GPU, the average elapsed time came out to be `463 ms ± 1.17 ms`.\n",
    "\n",
    "Let's explore how much work is being done. There are 101 transmits, 64 receiving elements, and 256x512 pixels. This amounts to having to process 101x64x256x512 ≈ 0.85 billion points. In 463 milliseconds, that approximately amounts to 1.8 billion points per second. This is fairly low for vbeam, and is likely due to a memory bottleneck."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import prod\n",
    "\n",
    "dimension_sizes = setup.size([\"transmits\", \"receivers\", \"points\"])\n",
    "total_points = prod(dimension_sizes)\n",
    "print(f\"Total number of processed points: {total_points:.1e}\")\n",
    "print(f\"Points processed per second: {total_points/0.463:.1e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering out Points by Apodization\n",
    "We are beamforming using RTB, which means that most pixels are weighted by 0 for each transmit. By using a `ApodizationFilteredScan` (that wraps our original scan) we only beamform the pixels that are actually included by RTB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vbeam.scan import ApodizationFilteredScan\n",
    "\n",
    "setup.scan  = ApodizationFilteredScan.from_setup(setup, [\"transmits\", \"points\"])\n",
    "\n",
    "beamformer = jax.jit(get_das_beamformer(setup))\n",
    "result = beamformer(**setup.data)\n",
    "plt.imshow(result.T, aspect=\"auto\", cmap=\"gray\")\n",
    "\n",
    "data = setup.data\n",
    "%timeit beamformer(**data).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the average elapsed time goes down to `16.8 ms ± 248 µs`; more than 27 times faster! This beamformer only have to process around a quarter of the pixels per transmit, for a total of 0.22 billion points. It processes around 13 billion points per second, which is actually 7 times more **efficient** — likely due to needing less memory, freeing up the memory bottleneck. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_sizes = setup.size([\"transmits\", \"receivers\", \"points\"])\n",
    "total_points = prod(dimension_sizes)\n",
    "print(f\"Total number of processed points: {total_points:.1e}\")\n",
    "print(f\"Points processed per second: {total_points/0.017:.1e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan Converting the Sector Scan Before Beamforming\n",
    "A final optimization that we will explore in this notebook is to scan convert the sector scan _before beamforming_. There are a lot of resolution redundancy close to the aperture of a sector scan, as the points are so close together. If we scan convert the grid before beamforming, these redundant pixels are merged together. Additionally, as the RTB apodization is quite wide close to the aperture, we get even more (relative) redundancy. We can combine the scan conversion and apodization filtering optimizations for an effect that it greater than the sum of its parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vbeam.scan import ScanConvertedSectorScan\n",
    "\n",
    "# Use both apodization filtering and scan conversion\n",
    "setup.scan.base_scan = ScanConvertedSectorScan(scan)\n",
    "\n",
    "beamformer = jax.jit(get_das_beamformer(setup))\n",
    "result = beamformer(**setup.data)\n",
    "plt.imshow(result.T, aspect=\"auto\", cmap=\"gray\")\n",
    "\n",
    "data = setup.data\n",
    "%timeit beamformer(**data).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using both the apodization filtering and pre scan conversion optimizations, the beamformer now takes `5.88 ms ± 155 µs`, on average. There are far fewer points as well, only about 7% of the original scan, or 26% of the apodization filtered scan. This beamformer processes around 9.7 billion points per second; slightly lower than the previous one, almost certainly due to under-utilizing the GPU cores. According to the `nvidia-smi` command, this beamformer had around 70% GPU utilization, while the previous one had around 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_sizes = setup.size([\"transmits\", \"receivers\", \"points\"])\n",
    "total_points = prod(dimension_sizes)\n",
    "print(f\"Total number of processed points: {total_points:.1e}\")\n",
    "print(f\"Points processed per second: {total_points/0.006:.1e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vbeam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
